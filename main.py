import cv2
import numpy as np
import os
import glob
from insightface.app import FaceAnalysis
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import ORJSONResponse
import uvicorn
from functools import lru_cache
from typing import Optional, Tuple
import asyncio
from concurrent.futures import ThreadPoolExecutor
from io import BytesIO
from PIL import Image

# ================== C·∫§U H√åNH ==================
EMBEDDINGS_DIR = "known_faces"

# ‚≠ê LOGIC ƒê√öNG: DUPLICATE_THRESHOLD ph·∫£i CAO H∆†N THRESHOLD
THRESHOLD = 0.50              # üéØ Nh·∫≠n di·ªán: 50% tr·ªü l√™n
DUPLICATE_THRESHOLD = 0.65    # üîí Tr√πng l·∫∑p: 65% tr·ªü l√™n (cao h∆°n 15%)

MAX_SIZE = 256
MAX_FILE_SIZE = 2_000_000
MODEL_NAME = "buffalo_sc"

# Preprocessing configs
USE_PILLOW = True
SKIP_GRAYSCALE = True
TARGET_FORMAT = "RGB"

# Thread pool
executor = ThreadPoolExecutor(max_workers=4)

# Messages
MSG_NOT_REGISTERED = "Ch∆∞a ƒëƒÉng k√Ω"
MSG_UNKNOWN = "Unknown"

os.makedirs(EMBEDDINGS_DIR, exist_ok=True)

# ================== VALIDATION ==================
def validate_thresholds():
    """Ki·ªÉm tra logic ng∆∞·ª°ng"""
    if DUPLICATE_THRESHOLD <= THRESHOLD:
        raise ValueError(
            f"‚ùå LOGIC SAI!\n"
            f"DUPLICATE_THRESHOLD ({DUPLICATE_THRESHOLD}) ph·∫£i CAO H∆†N THRESHOLD ({THRESHOLD})\n"
            f"L√Ω do: N·∫øu kh√¥ng, ng∆∞·ªùi ƒë·ªß ƒëi·ªÉm nh·∫≠n di·ªán s·∫Ω b·ªã ch·∫∑n khi ƒëƒÉng k√Ω!\n"
            f"Khuy·∫øn ngh·ªã: DUPLICATE = THRESHOLD + 0.10 ƒë·∫øn 0.15"
        )
    
    gap = DUPLICATE_THRESHOLD - THRESHOLD
    if gap < 0.05:
        print(f"‚ö†Ô∏è  C·∫£nh b√°o: Kho·∫£ng c√°ch gi·ªØa 2 ng∆∞·ª°ng qu√° nh·ªè ({gap:.2f})")
        print(f"    Khuy·∫øn ngh·ªã: T·ªëi thi·ªÉu 0.10 ƒë·ªÉ tr√°nh xung ƒë·ªôt")

validate_thresholds()

# ================== HELPER FUNCTIONS ==================
def extract_name_from_path(path: str) -> str:
    """Tr√≠ch xu·∫•t t√™n t·ª´ ƒë∆∞·ªùng d·∫´n file"""
    try:
        filename = os.path.basename(path)
        name_part = filename.split("_", 1)[1].replace(".npy", "")
        return name_part.replace("_", " ")
    except (IndexError, AttributeError):
        return MSG_UNKNOWN

def find_embedding_file(code: str) -> Optional[str]:
    """T√¨m file embedding theo code"""
    files = glob.glob(os.path.join(EMBEDDINGS_DIR, f"{code}_*.npy"))
    return files[0] if files else None

# ================== MODEL ==================
face_app = None

def get_model() -> FaceAnalysis:
    global face_app
    if face_app is None:
        print(f"ƒêang t·∫£i model: {MODEL_NAME} (det_size={MAX_SIZE})...")
        face_app = FaceAnalysis(name=MODEL_NAME, providers=['CPUExecutionProvider'])
        face_app.prepare(ctx_id=-1, det_size=(MAX_SIZE, MAX_SIZE))
        
        # Warm-up
        dummy = np.zeros((MAX_SIZE, MAX_SIZE, 3), dtype=np.uint8)
        face_app.get(dummy)
        print("Model s·∫µn s√†ng!")
    return face_app

# ================== CACHE ==================
embeddings_cache = {}

def preload_all_embeddings():
    """Load t·∫•t c·∫£ embeddings v√†o RAM"""
    global embeddings_cache
    files = glob.glob(os.path.join(EMBEDDINGS_DIR, "*.npy"))
    for path in files:
        try:
            code = os.path.basename(path).split("_", 1)[0]
            emb = np.load(path).astype(np.float32)
            name = extract_name_from_path(path)
            embeddings_cache[code] = (name, emb)
        except Exception as e:
            print(f"L·ªói load {path}: {e}")
    print(f"‚úì ƒê√£ load {len(embeddings_cache)} embeddings v√†o cache")

@lru_cache(maxsize=1000)
def get_embedding(code: str) -> Optional[Tuple[str, np.ndarray]]:
    """L·∫•y embedding t·ª´ cache"""
    return embeddings_cache.get(code)

def clear_cache():
    get_embedding.cache_clear()
    preload_all_embeddings()

# ‚≠ê ================== DUPLICATE DETECTION ==================
def check_duplicate_face(new_embedding: np.ndarray, exclude_code: str = None) -> Optional[Tuple[str, str, float]]:
    """
    Ki·ªÉm tra khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω ch∆∞a
    
    LOGIC:
    - So s√°nh v·ªõi T·∫§T C·∫¢ embeddings trong cache
    - N·∫øu similarity >= DUPLICATE_THRESHOLD ‚Üí Tr√πng l·∫∑p
    - DUPLICATE_THRESHOLD ph·∫£i cao h∆°n THRESHOLD ƒë·ªÉ tr√°nh m√¢u thu·∫´n
    
    Returns:
        None n·∫øu kh√¥ng tr√πng
        (code, name, similarity) n·∫øu tr√πng
    """
    max_similarity = 0.0
    duplicate_code = None
    duplicate_name = None
    
    for code, (name, known_emb) in embeddings_cache.items():
        # B·ªè qua code hi·ªán t·∫°i (d√πng cho update)
        if code == exclude_code:
            continue
        
        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
        similarity = float(np.dot(new_embedding, known_emb))
        
        if similarity > max_similarity:
            max_similarity = similarity
            duplicate_code = code
            duplicate_name = name
    
    # Tr·∫£ v·ªÅ th√¥ng tin n·∫øu v∆∞·ª£t ng∆∞·ª°ng
    if max_similarity >= DUPLICATE_THRESHOLD:
        return (duplicate_code, duplicate_name, max_similarity)
    
    return None

async def check_duplicate_face_async(new_embedding: np.ndarray, exclude_code: str = None):
    """Async wrapper for duplicate check"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, check_duplicate_face, new_embedding, exclude_code)

# ================== PREPROCESSING (ULTRA OPTIMIZED) ==================
def preprocess_pillow(file_bytes: bytes) -> np.ndarray:
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh v·ªõi PIL (nhanh nh·∫•t)"""
    if len(file_bytes) > MAX_FILE_SIZE:
        raise HTTPException(400, f"·∫¢nh qu√° l·ªõn (>{MAX_FILE_SIZE // 1_000_000}MB)")
    
    try:
        img_pil = Image.open(BytesIO(file_bytes))
        
        if img_pil.mode != 'RGB':
            img_pil = img_pil.convert('RGB')
        
        w, h = img_pil.size
        if max(w, h) > MAX_SIZE:
            img_pil.thumbnail((MAX_SIZE, MAX_SIZE), Image.LANCZOS)
        
        img_np = np.asarray(img_pil, dtype=np.uint8)
        
        if not img_np.flags['C_CONTIGUOUS']:
            img_np = np.ascontiguousarray(img_np)
        
        return img_np
        
    except Exception as e:
        raise HTTPException(400, f"·∫¢nh l·ªói: {str(e)}")

def preprocess_opencv(file_bytes: bytes) -> np.ndarray:
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh v·ªõi OpenCV (fallback)"""
    if len(file_bytes) > MAX_FILE_SIZE:
        raise HTTPException(400, f"·∫¢nh qu√° l·ªõn (>{MAX_FILE_SIZE // 1_000_000}MB)")
    
    arr = np.frombuffer(file_bytes, np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    
    if img is None:
        raise HTTPException(400, "·∫¢nh l·ªói")
    
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    h, w = img.shape[:2]
    if max(h, w) > MAX_SIZE:
        scale = MAX_SIZE / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    return img

def preprocess_sync(file_bytes: bytes) -> np.ndarray:
    """Ch·ªçn ph∆∞∆°ng ph√°p preprocessing t·ªëi ∆∞u nh·∫•t"""
    if USE_PILLOW:
        return preprocess_pillow(file_bytes)
    else:
        return preprocess_opencv(file_bytes)

async def preprocess(file_bytes: bytes) -> np.ndarray:
    """Async wrapper"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, preprocess_sync, file_bytes)

# ================== FACE DETECTION ==================
def detect_faces_sync(img: np.ndarray):
    """Detect faces (CPU-bound)"""
    return get_model().get(img)

async def detect_faces(img: np.ndarray):
    """Async wrapper"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, detect_faces_sync, img)

# ================== CONFIDENCE CLASSIFICATION ==================
def classify_confidence(score: float) -> dict:
    """Ph√¢n lo·∫°i m·ª©c ƒë·ªô tin c·∫≠y"""
    if score >= 0.70:
        return {
            "level": "CERTAIN",
            "label": "Ch·∫Øc ch·∫Øn",
            "color": "#22c55e",
            "emoji": "‚úÖ"
        }
    elif score >= 0.60:
        return {
            "level": "VERY_LIKELY", 
            "label": "R·∫•t c√≥ kh·∫£ nƒÉng",
            "color": "#84cc16",
            "emoji": "‚úì"
        }
    elif score >= 0.50:
        return {
            "level": "LIKELY",
            "label": "C√≥ kh·∫£ nƒÉng", 
            "color": "#eab308",
            "emoji": "‚ö†Ô∏è"
        }
    elif score >= 0.40:
        return {
            "level": "MAYBE",
            "label": "Nghi ng·ªù",
            "color": "#f97316", 
            "emoji": "‚ùì"
        }
    else:
        return {
            "level": "UNLIKELY",
            "label": "Kh√¥ng ph·∫£i",
            "color": "#ef4444",
            "emoji": "‚ùå"
        }

# ================== FASTAPI ==================
app = FastAPI(
    title="Face Recognition API (Ultra Fast + Duplicate Check)",
    default_response_class=ORJSONResponse
)

@app.on_event("startup")
async def startup_event():
    """Kh·ªüi ƒë·ªông: load model + embeddings"""
    print("‚è≥ ƒêang kh·ªüi ƒë·ªông...")
    get_model()
    preload_all_embeddings()
    print(f"‚úÖ S·∫µn s√†ng! (Preprocessing: {'PIL' if USE_PILLOW else 'OpenCV'})")
    print(f"üéØ Recognition threshold: {THRESHOLD} ({THRESHOLD*100:.0f}%)")
    print(f"üîí Duplicate threshold: {DUPLICATE_THRESHOLD} ({DUPLICATE_THRESHOLD*100:.0f}%)")
    print(f"üìä Gap: {DUPLICATE_THRESHOLD - THRESHOLD:.2f} (khuy·∫øn ngh·ªã: 0.10-0.15)\n")

@app.get("/")
async def home():
    return {
        "status": "running",
        "model": MODEL_NAME,
        "det_size": MAX_SIZE,
        "threshold": THRESHOLD,
        "duplicate_threshold": DUPLICATE_THRESHOLD,
        "threshold_gap": round(DUPLICATE_THRESHOLD - THRESHOLD, 2),
        "preprocessing": "PIL" if USE_PILLOW else "OpenCV",
        "cached_faces": len(embeddings_cache),
        "docs": "/docs"
    }

@app.post("/register")
async def register(
    code: str = Form(...), 
    name: str = Form(...), 
    file: UploadFile = File(...)
):
    """ƒêƒÉng k√Ω khu√¥n m·∫∑t m·ªõi v·ªõi ki·ªÉm tra tr√πng l·∫∑p"""
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(400, "File ph·∫£i l√† ·∫£nh (image/*)")

    # ‚≠ê Ki·ªÉm tra 1: Code ƒë√£ t·ªìn t·∫°i
    if code in embeddings_cache:
        old_name = embeddings_cache[code][0]
        raise HTTPException(400, f"M√£ {code} ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω cho: {old_name}")

    # X·ª≠ l√Ω ·∫£nh
    file_bytes = await file.read()
    img = await preprocess(file_bytes)
    faces = await detect_faces(img)
    
    if not faces:
        raise HTTPException(400, "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh")

    # L·∫•y embedding
    new_embedding = faces[0].normed_embedding.astype(np.float32)
    
    # ‚≠ê Ki·ªÉm tra 2: Khu√¥n m·∫∑t tr√πng l·∫∑p
    duplicate = await check_duplicate_face_async(new_embedding)
    if duplicate:
        dup_code, dup_name, similarity = duplicate
        raise HTTPException(
            409,  # Conflict
            f"Khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω!\n"
            f"M√£: {dup_code} | T√™n: {dup_name}\n"
            f"ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity*100:.1f}%"
        )

    # L∆∞u embedding
    safe_name = name.replace(' ', '_')
    path = os.path.join(EMBEDDINGS_DIR, f"{code}_{safe_name}.npy")
    
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(executor, np.save, path, new_embedding)
    
    # Update cache
    embeddings_cache[code] = (name, new_embedding)
    clear_cache()
    
    print(f"‚úì ƒêƒÉng k√Ω: {code} - {name}")
    return {
        "success": True, 
        "code": code, 
        "name": name,
        "message": "ƒêƒÉng k√Ω th√†nh c√¥ng"
    }

@app.post("/recognize")
async def recognize(
    code: str = Form(...), 
    file: UploadFile = File(...)
):
    """Nh·∫≠n di·ªán khu√¥n m·∫∑t"""
    cached = get_embedding(code)
    if not cached:
        return {
            "code": code, 
            "recognized": False, 
            "message": MSG_NOT_REGISTERED
        }

    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(400, "File ph·∫£i l√† ·∫£nh (image/*)")

    file_bytes = await file.read()
    img = await preprocess(file_bytes)
    faces = await detect_faces(img)
    
    if not faces:
        raise HTTPException(404, "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh")

    query_emb = faces[0].normed_embedding.astype(np.float32)
    name, known_emb = cached
    
    score = float(np.dot(query_emb, known_emb))
    confidence = round(score * 100, 2)
    recognized = score >= THRESHOLD
    
    # Ph√¢n lo·∫°i confidence
    conf_class = classify_confidence(score)

    return {
        "code": code,
        "name": name if recognized else MSG_UNKNOWN,
        "confidence": confidence,
        "confidence_level": conf_class["level"],
        "confidence_label": conf_class["label"],
        "recognized": recognized,
        "bbox": [int(x) for x in faces[0].bbox]
    }

@app.post("/check-duplicate")
async def check_duplicate_endpoint(file: UploadFile = File(...)):
    """
    ‚≠ê Endpoint m·ªõi: Ki·ªÉm tra khu√¥n m·∫∑t c√≥ tr√πng v·ªõi ai kh√¥ng
    (Kh√¥ng c·∫ßn code, ch·ªâ upload ·∫£nh)
    """
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(400, "File ph·∫£i l√† ·∫£nh (image/*)")

    file_bytes = await file.read()
    img = await preprocess(file_bytes)
    faces = await detect_faces(img)
    
    if not faces:
        raise HTTPException(400, "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh")

    new_embedding = faces[0].normed_embedding.astype(np.float32)
    duplicate = await check_duplicate_face_async(new_embedding)
    
    if duplicate:
        dup_code, dup_name, similarity = duplicate
        return {
            "is_duplicate": True,
            "matched_code": dup_code,
            "matched_name": dup_name,
            "similarity": round(similarity * 100, 2)
        }
    else:
        return {
            "is_duplicate": False,
            "message": "Khu√¥n m·∫∑t ch∆∞a ƒë∆∞·ª£c ƒëƒÉng k√Ω"
        }

@app.delete("/delete/{code}")
async def delete_by_code(code: str):
    """
    üóëÔ∏è X√≥a khu√¥n m·∫∑t theo m√£ code
    """
    # Ki·ªÉm tra code c√≥ t·ªìn t·∫°i kh√¥ng
    if code not in embeddings_cache:
        raise HTTPException(404, f"Kh√¥ng t√¨m th·∫•y m√£ {code}")
    
    # L·∫•y th√¥ng tin tr∆∞·ªõc khi x√≥a
    name, _ = embeddings_cache[code]
    
    # T√¨m v√† x√≥a file
    file_path = find_embedding_file(code)
    if file_path and os.path.exists(file_path):
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(executor, os.remove, file_path)
    
    # X√≥a kh·ªèi cache
    del embeddings_cache[code]
    clear_cache()
    
    print(f"üóëÔ∏è ƒê√£ x√≥a: {code} - {name}")
    return {
        "success": True,
        "deleted_code": code,
        "deleted_name": name,
        "message": f"ƒê√£ x√≥a {name} (m√£: {code})"
    }

@app.post("/delete-by-name")
async def delete_by_name(name: str = Form(...)):
    """
    üóëÔ∏è X√≥a khu√¥n m·∫∑t theo t√™n (c√≥ th·ªÉ x√≥a nhi·ªÅu ng∆∞·ªùi c√πng t√™n)
    """
    deleted = []
    name_lower = name.lower()
    
    # T√¨m t·∫•t c·∫£ code c√≥ t√™n tr√πng kh·ªõp
    codes_to_delete = []
    for code, (cached_name, _) in embeddings_cache.items():
        if cached_name.lower() == name_lower:
            codes_to_delete.append(code)
    
    if not codes_to_delete:
        raise HTTPException(404, f"Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi c√≥ t√™n '{name}'")
    
    # X√≥a t·ª´ng code
    for code in codes_to_delete:
        cached_name, _ = embeddings_cache[code]
        
        # X√≥a file
        file_path = find_embedding_file(code)
        if file_path and os.path.exists(file_path):
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(executor, os.remove, file_path)
        
        # X√≥a kh·ªèi cache
        del embeddings_cache[code]
        deleted.append({"code": code, "name": cached_name})
        print(f"üóëÔ∏è ƒê√£ x√≥a: {code} - {cached_name}")
    
    clear_cache()
    
    return {
        "success": True,
        "deleted_count": len(deleted),
        "deleted_records": deleted,
        "message": f"ƒê√£ x√≥a {len(deleted)} b·∫£n ghi c√≥ t√™n '{name}'"
    }

@app.delete("/delete-all")
async def delete_all(confirm: str = Form(...)):
    """
    üóëÔ∏è X√ìA T·∫§T C·∫¢ khu√¥n m·∫∑t (c·∫ßn x√°c nh·∫≠n b·∫±ng chu·ªói "DELETE_ALL")
    ‚ö†Ô∏è NGUY HI·ªÇM: H√†nh ƒë·ªông n√†y kh√¥ng th·ªÉ ho√†n t√°c!
    """
    if confirm != "DELETE_ALL":
        raise HTTPException(
            400, 
            "X√°c nh·∫≠n kh√¥ng ƒë√∫ng! Nh·∫≠p 'DELETE_ALL' ƒë·ªÉ x√≥a t·∫•t c·∫£"
        )
    
    if not embeddings_cache:
        return {
            "success": True,
            "deleted_count": 0,
            "message": "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ x√≥a"
        }
    
    deleted_count = len(embeddings_cache)
    deleted_list = [(code, name) for code, (name, _) in embeddings_cache.items()]
    
    # X√≥a t·∫•t c·∫£ file
    loop = asyncio.get_event_loop()
    files = glob.glob(os.path.join(EMBEDDINGS_DIR, "*.npy"))
    for file_path in files:
        await loop.run_in_executor(executor, os.remove, file_path)
    
    # X√≥a cache
    embeddings_cache.clear()
    clear_cache()
    
    print(f"üóëÔ∏è ƒê√É X√ìA T·∫§T C·∫¢: {deleted_count} khu√¥n m·∫∑t")
    return {
        "success": True,
        "deleted_count": deleted_count,
        "deleted_records": deleted_list[:10],  # Ch·ªâ hi·ªÉn th·ªã 10 ƒë·∫ßu ti√™n
        "message": f"ƒê√£ x√≥a to√†n b·ªô {deleted_count} khu√¥n m·∫∑t"
    }

@app.post("/delete-multiple")
async def delete_multiple(codes: str = Form(...)):
    """
    üóëÔ∏è X√≥a nhi·ªÅu khu√¥n m·∫∑t c√πng l√∫c
    codes: Chu·ªói m√£ c√°ch nhau b·ªüi d·∫•u ph·∫©y (vd: "001,002,003")
    """
    code_list = [c.strip() for c in codes.split(",") if c.strip()]
    
    if not code_list:
        raise HTTPException(400, "Danh s√°ch m√£ r·ªóng")
    
    deleted = []
    not_found = []
    
    for code in code_list:
        if code not in embeddings_cache:
            not_found.append(code)
            continue
        
        # L·∫•y th√¥ng tin
        name, _ = embeddings_cache[code]
        
        # X√≥a file
        file_path = find_embedding_file(code)
        if file_path and os.path.exists(file_path):
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(executor, os.remove, file_path)
        
        # X√≥a cache
        del embeddings_cache[code]
        deleted.append({"code": code, "name": name})
        print(f"üóëÔ∏è ƒê√£ x√≥a: {code} - {name}")
    
    clear_cache()
    
    return {
        "success": True,
        "deleted_count": len(deleted),
        "deleted_records": deleted,
        "not_found": not_found,
        "message": f"ƒê√£ x√≥a {len(deleted)}/{len(code_list)} b·∫£n ghi"
    }

@app.get("/list")
async def list_all():
    """
    üìã Li·ªát k√™ t·∫•t c·∫£ khu√¥n m·∫∑t ƒë√£ ƒëƒÉng k√Ω
    """
    if not embeddings_cache:
        return {
            "total": 0,
            "faces": [],
            "message": "Ch∆∞a c√≥ khu√¥n m·∫∑t n√†o ƒë∆∞·ª£c ƒëƒÉng k√Ω"
        }
    
    faces = []
    for code, (name, _) in embeddings_cache.items():
        file_path = find_embedding_file(code)
        file_size = os.path.getsize(file_path) if file_path else 0
        
        faces.append({
            "code": code,
            "name": name,
            "file_size_kb": round(file_size / 1024, 2)
        })
    
    # S·∫Øp x·∫øp theo code
    faces.sort(key=lambda x: x["code"])
    
    return {
        "total": len(faces),
        "faces": faces
    }

@app.get("/stats")
async def stats():
    """Th·ªëng k√™ h·ªá th·ªëng"""
    return {
        "total_registered": len(embeddings_cache),
        "preprocessing": "PIL (LANCZOS)" if USE_PILLOW else "OpenCV (LINEAR)",
        "skip_grayscale": SKIP_GRAYSCALE,
        "max_size": MAX_SIZE,
        "threshold": THRESHOLD,
        "duplicate_threshold": DUPLICATE_THRESHOLD,
        "threshold_gap": round(DUPLICATE_THRESHOLD - THRESHOLD, 2),
        "logic_valid": DUPLICATE_THRESHOLD > THRESHOLD
    }

@app.get("/test-thresholds")
async def test_thresholds():
    """
    üß™ Test c√°c ng∆∞·ª°ng v·ªõi v√≠ d·ª•
    """
    test_scores = [0.85, 0.75, 0.65, 0.55, 0.45, 0.35]
    results = []
    
    for score in test_scores:
        conf_class = classify_confidence(score)
        results.append({
            "similarity": score,
            "confidence_pct": round(score * 100, 1),
            "would_recognize": score >= THRESHOLD,
            "would_block_duplicate": score >= DUPLICATE_THRESHOLD,
            "classification": conf_class["label"],
            "emoji": conf_class["emoji"]
        })
    
    return {
        "threshold_config": {
            "recognition": THRESHOLD,
            "duplicate": DUPLICATE_THRESHOLD,
            "gap": round(DUPLICATE_THRESHOLD - THRESHOLD, 2)
        },
        "test_results": results,
        "explanation": {
            "recognition_zone": f"‚â• {THRESHOLD:.2f} ‚Üí Nh·∫≠n di·ªán th√†nh c√¥ng",
            "gray_zone": f"{THRESHOLD:.2f} - {DUPLICATE_THRESHOLD:.2f} ‚Üí Nh·∫≠n di·ªán OK, c√≥ th·ªÉ ƒëƒÉng k√Ω ng∆∞·ªùi kh√°c",
            "duplicate_zone": f"‚â• {DUPLICATE_THRESHOLD:.2f} ‚Üí Ch·∫∑n ƒëƒÉng k√Ω (tr√πng l·∫∑p)"
        }
    }

# ================== RUN ==================
if __name__ == "__main__":
    print(f"\nüöÄ Face Recognition API (ULTRA FAST + DUPLICATE CHECK)")
    print(f"Model: {MODEL_NAME} | Size: {MAX_SIZE}px")
    print(f"Preprocessing: {'PIL (3x faster)' if USE_PILLOW else 'OpenCV'}")
    print(f"Recognition threshold: {THRESHOLD} ({THRESHOLD*100:.0f}%)")
    print(f"Duplicate threshold: {DUPLICATE_THRESHOLD} ({DUPLICATE_THRESHOLD*100:.0f}%)")
    print(f"Gap: {DUPLICATE_THRESHOLD - THRESHOLD:.2f}\n")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        workers=2,
        reload=False,
        log_level="warning"
    )