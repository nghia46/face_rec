import cv2
import numpy as np
import os
import glob
from insightface.app import FaceAnalysis
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from typing import Optional, Tuple
import asyncio
from concurrent.futures import ThreadPoolExecutor
from io import BytesIO
from PIL import Image
import traceback

# ================== C·∫§U H√åNH ==================
EMBEDDINGS_DIR = "known_faces"
THRESHOLD = 0.50              
DUPLICATE_THRESHOLD = 0.65    
MAX_SIZE = 256
MAX_FILE_SIZE = 2_000_000
MODEL_NAME = "buffalo_sc"

USE_PILLOW = True
SKIP_GRAYSCALE = True
TARGET_FORMAT = "RGB"

executor = ThreadPoolExecutor(max_workers=4)

MSG_NOT_REGISTERED = "Ch∆∞a ƒëƒÉng k√Ω"
MSG_UNKNOWN = "Unknown"

os.makedirs(EMBEDDINGS_DIR, exist_ok=True)

# ================== VALIDATION ==================
def validate_thresholds():
    if DUPLICATE_THRESHOLD <= THRESHOLD:
        raise ValueError(
            f"LOGIC SAI!\n"
            f"DUPLICATE_THRESHOLD ({DUPLICATE_THRESHOLD}) ph·∫£i CAO H∆†N THRESHOLD ({THRESHOLD})\n"
            f"L√Ω do: N·∫øu kh√¥ng, ng∆∞·ªùi ƒë·ªß ƒëi·ªÉm nh·∫≠n di·ªán s·∫Ω b·ªã ch·∫∑n khi ƒëƒÉng k√Ω!\n"
            f"Khuy·∫øn ngh·ªã: DUPLICATE = THRESHOLD + 0.10 ƒë·∫øn 0.15"
        )
    gap = DUPLICATE_THRESHOLD - THRESHOLD
    if gap < 0.05:
        print(f"C·∫£nh b√°o: Kho·∫£ng c√°ch gi·ªØa 2 ng∆∞·ª°ng qu√° nh·ªè ({gap:.2f})")
        print(f"    Khuy·∫øn ngh·ªã: T·ªëi thi·ªÉu 0.10 ƒë·ªÉ tr√°nh xung ƒë·ªôt")

validate_thresholds()

# ================== HELPER FUNCTIONS ==================
def extract_name_from_path(path: str) -> str:
    try:
        filename = os.path.basename(path)
        name_part = filename.split("_", 1)[1].replace(".npy", "")
        return name_part.replace("_", " ")
    except (IndexError, AttributeError):
        return MSG_UNKNOWN

def find_embedding_file(code: str) -> Optional[str]:
    files = glob.glob(os.path.join(EMBEDDINGS_DIR, f"{code}_*.npy"))
    return files[0] if files else None

# ================== MODEL ==================
face_app = None

def get_model() -> FaceAnalysis:
    global face_app
    if face_app is None:
        try:
            print(f"ƒêang t·∫£i model: {MODEL_NAME} (det_size={MAX_SIZE})...")
            face_app = FaceAnalysis(name=MODEL_NAME, providers=['CPUExecutionProvider'])
            face_app.prepare(ctx_id=-1, det_size=(MAX_SIZE, MAX_SIZE))
            
            dummy = np.zeros((MAX_SIZE, MAX_SIZE, 3), dtype=np.uint8)
            face_app.get(dummy)
            print("‚úÖ Model s·∫µn s√†ng!")
        except Exception as e:
            print(f"‚ùå L·ªñI T·∫¢I MODEL: {e}")
            traceback.print_exc()
            raise
    return face_app

# ================== CACHE ==================
embeddings_cache = {}

def preload_all_embeddings():
    global embeddings_cache
    embeddings_cache.clear()
    files = glob.glob(os.path.join(EMBEDDINGS_DIR, "*.npy"))
    loaded = 0
    for path in files:
        try:
            filename = os.path.basename(path)
            code = filename.split("_", 1)[0]
            emb = np.load(path).astype(np.float32)
            name = extract_name_from_path(path)
            embeddings_cache[code] = (name, emb)
            loaded += 1
        except Exception as e:
            print(f"[ERROR] L·ªói load {path}: {e}")
    print(f"‚úÖ ƒê√£ load {loaded}/{len(files)} embeddings v√†o cache")

def get_embedding(code: str) -> Optional[Tuple[str, np.ndarray]]:
    return embeddings_cache.get(code)

def refresh_cache():
    preload_all_embeddings()

# ================== DUPLICATE DETECTION ==================
def check_duplicate_face(new_embedding: np.ndarray, exclude_code: str = None) -> Optional[Tuple[str, str, float]]:
    max_similarity = 0.0
    duplicate_code = None
    duplicate_name = None
    
    for code, (name, known_emb) in embeddings_cache.items():
        if code == exclude_code:
            continue
        similarity = float(np.dot(new_embedding, known_emb))
        if similarity > max_similarity:
            max_similarity = similarity
            duplicate_code = code
            duplicate_name = name
    
    if max_similarity >= DUPLICATE_THRESHOLD:
        return (duplicate_code, duplicate_name, max_similarity)
    return None

async def check_duplicate_face_async(new_embedding: np.ndarray, exclude_code: str = None):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, check_duplicate_face, new_embedding, exclude_code)

# ================== PREPROCESSING ==================
def preprocess_pillow(file_bytes: bytes) -> np.ndarray:
    if len(file_bytes) > MAX_FILE_SIZE:
        raise HTTPException(400, f"·∫¢nh qu√° l·ªõn (>{MAX_FILE_SIZE // 1_000_000}MB)")
    try:
        img_pil = Image.open(BytesIO(file_bytes))
        if img_pil.mode != 'RGB':
            img_pil = img_pil.convert('RGB')
        w, h = img_pil.size
        if max(w, h) > MAX_SIZE:
            img_pil.thumbnail((MAX_SIZE, MAX_SIZE), Image.LANCZOS)
        img_np = np.asarray(img_pil, dtype=np.uint8)
        if not img_np.flags['C_CONTIGUOUS']:
            img_np = np.ascontiguousarray(img_np)
        return img_np
    except Exception as e:
        raise HTTPException(400, f"·∫¢nh l·ªói: {str(e)}")

def preprocess_opencv(file_bytes: bytes) -> np.ndarray:
    if len(file_bytes) > MAX_FILE_SIZE:
        raise HTTPException(400, f"·∫¢nh qu√° l·ªõn (>{MAX_FILE_SIZE // 1_000_000}MB)")
    arr = np.frombuffer(file_bytes, np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if img is None:
        raise HTTPException(400, "·∫¢nh l·ªói")
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w = img.shape[:2]
    if max(h, w) > MAX_SIZE:
        scale = MAX_SIZE / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    return img

def preprocess_sync(file_bytes: bytes) -> np.ndarray:
    return preprocess_pillow(file_bytes) if USE_PILLOW else preprocess_opencv(file_bytes)

async def preprocess(file_bytes: bytes) -> np.ndarray:
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, preprocess_sync, file_bytes)

# ================== FACE DETECTION ==================
def detect_faces_sync(img: np.ndarray):
    return get_model().get(img)

async def detect_faces(img: np.ndarray):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, detect_faces_sync, img)

# ================== CONFIDENCE CLASSIFICATION ==================
def classify_confidence(score: float) -> dict:
    if score >= 0.70:
        return {"level": "CERTAIN", "label": "Ch·∫Øc ch·∫Øn", "color": "#22c55e", "emoji": "Ch·∫Øc ch·∫Øn"}
    elif score >= 0.60:
        return {"level": "VERY_LIKELY", "label": "R·∫•t c√≥ kh·∫£ nƒÉng", "color": "#84cc16", "emoji": "R·∫•t c√≥ kh·∫£ nƒÉng"}
    elif score >= 0.50:
        return {"level": "LIKELY", "label": "C√≥ kh·∫£ nƒÉng", "color": "#eab308", "emoji": "C√≥ kh·∫£ nƒÉng"}
    elif score >= 0.40:
        return {"level": "MAYBE", "label": "Nghi ng·ªù", "color": "#f97316", "emoji": "Nghi ng·ªù"}
    else:
        return {"level": "UNLIKELY", "label": "Kh√¥ng ph·∫£i", "color": "#ef4444", "emoji": "Kh√¥ng ph·∫£i"}

# ================== FASTAPI ==================
app = FastAPI(
    title="Face Recognition API",
    description="Ultra Fast Face Recognition with Duplicate Detection",
    version="1.0.0"
)

# Add CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ ERROR HANDLER - B·∫ÆT M·ªåI L·ªñI 500
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    print(f"‚ùå GLOBAL ERROR: {exc}")
    traceback.print_exc()
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": str(exc),
            "type": type(exc).__name__
        }
    )

@app.on_event("startup")
async def startup_event():
    try:
        print("üöÄ ƒêang kh·ªüi ƒë·ªông...")
        print(f"Preprocessing: {'PIL' if USE_PILLOW else 'OpenCV'}")
        print(f"Recognition threshold: {THRESHOLD} ({THRESHOLD*100:.0f}%)")
        print(f"Duplicate threshold: {DUPLICATE_THRESHOLD} ({DUPLICATE_THRESHOLD*100:.0f}%)")
        
        # Load embeddings first (kh√¥ng c·∫ßn model)
        preload_all_embeddings()
        
        # Model s·∫Ω ƒë∆∞·ª£c load lazy khi c·∫ßn
        print("‚úÖ API s·∫µn s√†ng! Model s·∫Ω load khi c√≥ request ƒë·∫ßu ti√™n.")
        
    except Exception as e:
        print(f"‚ùå L·ªñI KH·ªûI ƒê·ªòNG: {e}")
        traceback.print_exc()

# ‚úÖ HEALTH CHECK - KH√îNG C·∫¶N MODEL
@app.get("/")
async def home():
    return {
        "status": "running",
        "message": "Face Recognition API is running",
        "model": MODEL_NAME,
        "det_size": MAX_SIZE,
        "threshold": THRESHOLD,
        "duplicate_threshold": DUPLICATE_THRESHOLD,
        "cached_faces": len(embeddings_cache),
        "model_loaded": face_app is not None,
        "docs": "/docs"
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "cached_faces": len(embeddings_cache),
        "model_loaded": face_app is not None
    }

@app.post("/register")
async def register(
    code: str = Form(...),
    name: str = Form(...),
    file: UploadFile = File(...)
):
    try:
        if not file.content_type or not file.content_type.startswith("image/"):
            raise HTTPException(400, "File ph·∫£i l√† ·∫£nh (image/*)")
        
        if code in embeddings_cache:
            old_name = embeddings_cache[code][0]
            raise HTTPException(400, f"M√£ {code} ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω cho: {old_name}")
        
        file_bytes = await file.read()
        img = await preprocess(file_bytes)
        faces = await detect_faces(img)
        
        if not faces:
            raise HTTPException(400, "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh")
        
        new_embedding = faces[0].normed_embedding.astype(np.float32)
        duplicate = await check_duplicate_face_async(new_embedding)
        
        if duplicate:
            dup_code, dup_name, similarity = duplicate
            raise HTTPException(
                409,
                f"Khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω!\nM√£: {dup_code} | T√™n: {dup_name}\nƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity*100:.1f}%"
            )
        
        safe_name = name.replace(' ', '_')
        path = os.path.join(EMBEDDINGS_DIR, f"{code}_{safe_name}.npy")
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(executor, np.save, path, new_embedding)
        
        embeddings_cache[code] = (name, new_embedding)
        
        print(f"‚úÖ ƒêƒÉng k√Ω: {code} - {name}")
        return {
            "success": True,
            "code": code,
            "name": name,
            "message": "ƒêƒÉng k√Ω th√†nh c√¥ng"
        }
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Register error: {e}")
        traceback.print_exc()
        raise HTTPException(500, f"L·ªói ƒëƒÉng k√Ω: {str(e)}")

@app.post("/recognize")
async def recognize(
    code: str = Form(...),
    file: UploadFile = File(...)
):
    try:
        cached = get_embedding(code)
        if not cached:
            return {
                "code": code,
                "recognized": False,
                "message": MSG_NOT_REGISTERED
            }
        
        if not file.content_type or not file.content_type.startswith("image/"):
            raise HTTPException(400, "File ph·∫£i l√† ·∫£nh (image/*)")
        
        file_bytes = await file.read()
        img = await preprocess(file_bytes)
        faces = await detect_faces(img)
        
        if not faces:
            raise HTTPException(404, "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh")
        
        query_emb = faces[0].normed_embedding.astype(np.float32)
        name, known_emb = cached
        score = float(np.dot(query_emb, known_emb))
        confidence = round(score * 100, 2)
        recognized = score >= THRESHOLD
        conf_class = classify_confidence(score)
        
        return {
            "code": code,
            "name": name if recognized else MSG_UNKNOWN,
            "confidence": confidence,
            "confidence_level": conf_class["level"],
            "confidence_label": conf_class["label"],
            "recognized": recognized,
            "bbox": [int(x) for x in faces[0].bbox]
        }
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Recognize error: {e}")
        traceback.print_exc()
        raise HTTPException(500, f"L·ªói nh·∫≠n di·ªán: {str(e)}")

@app.get("/list")
async def list_all():
    if not embeddings_cache:
        return {"total": 0, "faces": [], "message": "Ch∆∞a c√≥ khu√¥n m·∫∑t n√†o ƒë∆∞·ª£c ƒëƒÉng k√Ω"}
    
    faces = []
    for code, (name, _) in embeddings_cache.items():
        file_path = find_embedding_file(code)
        file_size = os.path.getsize(file_path) if file_path else 0
        faces.append({
            "code": code,
            "name": name,
            "file_size_kb": round(file_size / 1024, 2)
        })
    faces.sort(key=lambda x: x["code"])
    return {"total": len(faces), "faces": faces}

@app.delete("/delete/{code}")
async def delete_by_code(code: str):
    if code not in embeddings_cache:
        raise HTTPException(404, f"Kh√¥ng t√¨m th·∫•y m√£ {code}")
    
    name, _ = embeddings_cache[code]
    file_path = find_embedding_file(code)
    if file_path and os.path.exists(file_path):
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(executor, os.remove, file_path)
    
    del embeddings_cache[code]
    
    print(f"‚úÖ ƒê√£ x√≥a: {code} - {name}")
    return {
        "success": True,
        "deleted_code": code,
        "deleted_name": name,
        "message": f"ƒê√£ x√≥a {name} (m√£: {code})"
    }

# ================== RUN ==================
if __name__ == "__main__":
    print(f"\nüöÄ Face Recognition API")
    print(f"Model: {MODEL_NAME} | Size: {MAX_SIZE}px")
    print(f"Preprocessing: {'PIL (3x faster)' if USE_PILLOW else 'OpenCV'}")
    print(f"Thresholds: Recognition={THRESHOLD} | Duplicate={DUPLICATE_THRESHOLD}\n")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        workers=1,  # ‚úÖ CH·ªà D√ôNG 1 WORKER
        reload=False,
        log_level="info"  # ‚úÖ ƒê·ªîI TH√ÄNH INFO ƒê·ªÇ XEM LOG
    )